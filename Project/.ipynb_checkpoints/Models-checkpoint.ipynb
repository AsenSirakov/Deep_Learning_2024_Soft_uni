{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d38ff368-1acb-436e-a25c-17c64062a52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asens\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asens\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [19:55<00:00,  1.20s/it]\n",
      "Validation: 100%|██████████| 250/250 [04:02<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0742, Val Loss: 0.0265, Val Accuracy: 0.9915\n",
      "Saved Best Model\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [16:20<00:00,  1.02it/s]\n",
      "Validation: 100%|██████████| 250/250 [02:14<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0278, Val Loss: 0.0189, Val Accuracy: 0.9937\n",
      "Saved Best Model\n",
      "Training Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Custom Dataset ---\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.annotations = csv_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.annotations.iloc[idx, 0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = torch.tensor(int(self.annotations.iloc[idx, 1]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# --- Data Preparation ---\n",
    "# Load and clean CSV\n",
    "csv_path = \"train.csv\"  # Adjust this to the path of your cleaned CSV file\n",
    "train_df = pd.read_csv(csv_path)\n",
    "train_df[\"file_name\"] = train_df[\"file_name\"].str.replace(\"train_data/\", \"\", regex=False)  # Ensure no redundant prefixes\n",
    "train_df = train_df.drop(columns=[\"Unnamed: 0\"])  # Remove unnecessary column\n",
    "\n",
    "# Train-validation split\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=42)\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "img_dir = \"train_data\"  # Directory containing all images\n",
    "train_dataset = ImageDataset(train_df, img_dir, transform=train_transform)\n",
    "val_dataset = ImageDataset(val_df, img_dir, transform=val_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# --- Define ResNet50 Model ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1)  # Binary classification\n",
    "model = model.to(device)\n",
    "\n",
    "# --- Loss and Optimizer ---\n",
    "criterion = nn.BCEWithLogitsLoss()  # Combines sigmoid and binary cross-entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # Decay learning rate\n",
    "\n",
    "# --- Training and Validation Loops ---\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_outputs = torch.sigmoid(torch.tensor(np.concatenate(all_outputs))).numpy()  # Convert logits to probabilities\n",
    "\n",
    "    return epoch_loss, all_labels, all_outputs\n",
    "\n",
    "# --- Main Training Script ---\n",
    "num_epochs = 2\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_labels, val_outputs = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Calculate metrics\n",
    "    val_preds = (val_outputs > 0.5).astype(int)\n",
    "    accuracy = (val_preds == val_labels).mean()\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_resnet50.pth\")\n",
    "        print(\"Saved Best Model\")\n",
    "\n",
    "print(\"Training Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f268186e-4806-4de6-bdb9-88162a501b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torchvision import transforms, models\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tqdm import tqdm\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # --- Custom Dataset ---\n",
    "# class ImageDataset(Dataset):\n",
    "#     def __init__(self, csv_file, img_dir, transform=None):\n",
    "#         self.annotations = csv_file\n",
    "#         self.img_dir = img_dir\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.annotations)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = os.path.join(self.img_dir, self.annotations.iloc[idx, 0])\n",
    "#         image = Image.open(img_path).convert(\"RGB\")\n",
    "#         label = torch.tensor(int(self.annotations.iloc[idx, 1]))\n",
    "\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "\n",
    "#         return image, label\n",
    "\n",
    "# # --- Early Stopping ---\n",
    "# class EarlyStopping:\n",
    "#     def __init__(self, patience=5, verbose=True):\n",
    "#         \"\"\"\n",
    "#         Early stopping to stop training when validation loss doesn't improve.\n",
    "#         Args:\n",
    "#         - patience (int): Number of epochs to wait for improvement.\n",
    "#         - verbose (bool): Whether to print messages.\n",
    "#         \"\"\"\n",
    "#         self.patience = patience\n",
    "#         self.verbose = verbose\n",
    "#         self.counter = 0\n",
    "#         self.best_loss = None\n",
    "#         self.early_stop = False\n",
    "\n",
    "#     def __call__(self, val_loss, model, path=\"best_model.pth\"):\n",
    "#         if self.best_loss is None or val_loss < self.best_loss:\n",
    "#             self.best_loss = val_loss\n",
    "#             self.counter = 0\n",
    "#             torch.save(model.state_dict(), path)\n",
    "#             if self.verbose:\n",
    "#                 print(f\"Validation loss improved to {val_loss:.4f}. Model saved!\")\n",
    "#         else:\n",
    "#             self.counter += 1\n",
    "#             if self.verbose:\n",
    "#                 print(f\"No improvement. EarlyStopping counter: {self.counter}/{self.patience}\")\n",
    "#             if self.counter >= self.patience:\n",
    "#                 self.early_stop = True\n",
    "\n",
    "# # --- Data Preparation ---\n",
    "# # Load and clean CSV\n",
    "# csv_path = \"train.csv\"  # Adjust this to the path of your cleaned CSV file\n",
    "# train_df = pd.read_csv(csv_path)\n",
    "# train_df[\"file_name\"] = train_df[\"file_name\"].str.replace(\"train_data/\", \"\", regex=False)  # Ensure no redundant prefixes\n",
    "# train_df = train_df.drop(columns=[\"Unnamed: 0\"])  # Remove unnecessary column\n",
    "\n",
    "# # Train-validation split\n",
    "# train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=42)\n",
    "\n",
    "# # Define transformations\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(10),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "\n",
    "# val_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "\n",
    "# # Create datasets\n",
    "# img_dir = \"train_data\"  # Directory containing all images\n",
    "# train_dataset = ImageDataset(train_df, img_dir, transform=train_transform)\n",
    "# val_dataset = ImageDataset(val_df, img_dir, transform=val_transform)\n",
    "\n",
    "# # Create dataloaders\n",
    "# batch_size = 64\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# # --- Define ResNet50 Model ---\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = models.resnet50(pretrained=True)\n",
    "# num_features = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_features, 1)  # Binary classification\n",
    "# model = model.to(device)\n",
    "\n",
    "# # --- Loss and Optimizer ---\n",
    "# criterion = nn.BCEWithLogitsLoss()  # Combines sigmoid and binary cross-entropy\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # Decay learning rate\n",
    "\n",
    "# # --- Training and Validation Functions ---\n",
    "# def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "\n",
    "#     for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "#         images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         running_loss += loss.item() * images.size(0)\n",
    "\n",
    "#     epoch_loss = running_loss / len(train_loader.dataset)\n",
    "#     return epoch_loss\n",
    "\n",
    "# def validate(model, val_loader, criterion, device):\n",
    "#     model.eval()\n",
    "#     running_loss = 0.0\n",
    "#     all_labels = []\n",
    "#     all_outputs = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "#             images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             all_labels.append(labels.cpu().numpy())\n",
    "#             all_outputs.append(outputs.cpu().numpy())\n",
    "\n",
    "#     epoch_loss = running_loss / len(val_loader.dataset)\n",
    "#     all_labels = np.concatenate(all_labels)\n",
    "#     all_outputs = torch.sigmoid(torch.tensor(np.concatenate(all_outputs))).numpy()  # Convert logits to probabilities\n",
    "\n",
    "#     return epoch_loss, all_labels, all_outputs\n",
    "\n",
    "# # --- Main Training Script ---\n",
    "# num_epochs = 20\n",
    "# best_val_loss = float(\"inf\")\n",
    "# early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "# # Initialize lists to store metrics\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "# val_accuracies = []\n",
    "\n",
    "# # Plotting setup\n",
    "# plt.ion()\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "#     # Train for one epoch\n",
    "#     train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "#     train_losses.append(train_loss)\n",
    "\n",
    "#     # Validate after each epoch\n",
    "#     val_loss, val_labels, val_outputs = validate(model, val_loader, criterion, device)\n",
    "#     val_losses.append(val_loss)\n",
    "\n",
    "#     # Calculate Validation Accuracy\n",
    "#     val_preds = (val_outputs > 0.5).astype(int)\n",
    "#     accuracy = (val_preds == val_labels).mean()\n",
    "#     val_accuracies.append(accuracy)\n",
    "\n",
    "#     # Print metrics for this epoch\n",
    "#     print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "#     # Update learning rate\n",
    "#     scheduler.step()\n",
    "\n",
    "#     # Early stopping\n",
    "#     early_stopping(val_loss, model, path=\"best_resnet501.pth\")\n",
    "#     if early_stopping.early_stop:\n",
    "#         print(\"Early stopping triggered!\")\n",
    "#         break\n",
    "\n",
    "#     # Update live plot\n",
    "#     ax.clear()\n",
    "#     ax.plot(range(1, len(train_losses) + 1), train_losses, label=\"Train Loss\", marker=\"o\")\n",
    "#     ax.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\", marker=\"o\")\n",
    "#     ax.set_xlabel(\"Epochs\")\n",
    "#     ax.set_ylabel(\"Loss\")\n",
    "#     ax.set_title(\"Training and Validation Loss\")\n",
    "#     ax.legend()\n",
    "#     plt.draw()\n",
    "#     plt.pause(0.01)\n",
    "\n",
    "# # Save metrics for analysis\n",
    "# metrics = {\n",
    "#     \"train_loss\": train_losses,\n",
    "#     \"val_loss\": val_losses,\n",
    "#     \"val_accuracy\": val_accuracies\n",
    "# }\n",
    "\n",
    "# with open(\"training_metrics.json\", \"w\") as f:\n",
    "#     json.dump(metrics, f)\n",
    "# print(\"Saved training metrics to 'training_metrics.json'\")\n",
    "\n",
    "# plt.ioff()\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Training Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1263b251-d6be-49ba-bec4-78082cfb18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# --- Custom Dataset ---\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.annotations = csv_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.annotations.iloc[idx, 0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = torch.tensor(int(self.annotations.iloc[idx, 1]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# --- Early Stopping ---\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model, optimizer, scheduler, epoch, path=\"checkpoint.pth\"):\n",
    "        if self.best_loss is None or val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                \"best_loss\": self.best_loss\n",
    "            }, path)\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss improved to {val_loss:.4f}. Checkpoint saved!\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"No improvement. EarlyStopping counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# --- Data Preparation ---\n",
    "csv_path = \"train.csv\"\n",
    "train_df = pd.read_csv(csv_path)\n",
    "train_df[\"file_name\"] = train_df[\"file_name\"].str.replace(\"train_data/\", \"\", regex=False)\n",
    "train_df = train_df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=42)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "img_dir = \"train_data\"\n",
    "train_dataset = ImageDataset(train_df, img_dir, transform=train_transform)\n",
    "val_dataset = ImageDataset(val_df, img_dir, transform=val_transform)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# --- Model Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# --- Resume Training ---\n",
    "def load_checkpoint(path, model, optimizer, scheduler):\n",
    "    if os.path.exists(path):\n",
    "        checkpoint = torch.load(path)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        best_val_loss = checkpoint[\"best_loss\"]\n",
    "        print(f\"Checkpoint loaded: Resuming from epoch {start_epoch} with best_val_loss {best_val_loss:.4f}\")\n",
    "        return start_epoch, best_val_loss\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting from scratch.\")\n",
    "        return 0, float(\"inf\")\n",
    "\n",
    "# --- Training and Validation Functions ---\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_outputs = torch.sigmoid(torch.tensor(np.concatenate(all_outputs))).numpy()\n",
    "\n",
    "    return epoch_loss, all_labels, all_outputs\n",
    "\n",
    "# --- Main Training Script ---\n",
    "num_epochs = 20\n",
    "checkpoint_path = \"checkpoint.pth\"\n",
    "start_epoch, best_val_loss = load_checkpoint(checkpoint_path, model, optimizer, scheduler)\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "plt.ion()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    val_loss, val_labels, val_outputs = validate(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    val_preds = (val_outputs > 0.5).astype(int)\n",
    "    accuracy = (val_preds == val_labels).mean()\n",
    "    val_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    early_stopping(val_loss, model, optimizer, scheduler, epoch, path=checkpoint_path)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "    ax.clear()\n",
    "    ax.plot(range(1, len(train_losses) + 1), train_losses, label=\"Train Loss\", marker=\"o\")\n",
    "    ax.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\", marker=\"o\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"Training and Validation Loss\")\n",
    "    ax.legend()\n",
    "    plt.draw()\n",
    "    plt.pause(0.01)\n",
    "\n",
    "metrics = {\n",
    "    \"train_loss\": train_losses,\n",
    "    \"val_loss\": val_losses,\n",
    "    \"val_accuracy\": val_accuracies\n",
    "}\n",
    "\n",
    "with open(\"training_metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f)\n",
    "print(\"Saved training metrics to 'training_metrics.json'\")\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26351664-79d7-4baf-be27-938e560a2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GradCAM:\n",
    "#     def __init__(self, model, target_layer):\n",
    "#         \"\"\"\n",
    "#         Initialize Grad-CAM with the model and the target layer.\n",
    "#         Args:\n",
    "#         - model: Trained PyTorch model.\n",
    "#         - target_layer: Layer to compute Grad-CAM for.\n",
    "#         \"\"\"\n",
    "#         self.model = model\n",
    "#         self.target_layer = target_layer\n",
    "#         self.gradients = None\n",
    "\n",
    "#         # Hook to get gradients\n",
    "#         target_layer.register_backward_hook(self.save_gradients)\n",
    "\n",
    "#     def save_gradients(self, module, grad_input, grad_output):\n",
    "#         self.gradients = grad_output[0]\n",
    "\n",
    "#     def generate_heatmap(self, feature_maps, gradients):\n",
    "#         \"\"\"\n",
    "#         Generate a heatmap using feature maps and gradients.\n",
    "#         \"\"\"\n",
    "#         weights = gradients.mean(dim=(2, 3), keepdim=True)  # Global average pooling\n",
    "#         cam = (weights * feature_maps).sum(dim=1, keepdim=True)  # Weighted sum\n",
    "#         cam = torch.relu(cam)  # ReLU to keep only positive values\n",
    "#         cam = cam.squeeze().cpu().detach().numpy()\n",
    "#         cam = (cam - cam.min()) / (cam.max() - cam.min())  # Normalize to [0, 1]\n",
    "#         return cam\n",
    "\n",
    "#     def __call__(self, input_image, target_class):\n",
    "#         \"\"\"\n",
    "#         Compute Grad-CAM for a given input and target class.\n",
    "#         Args:\n",
    "#         - input_image: Preprocessed input tensor of shape [1, C, H, W].\n",
    "#         - target_class: Class index for which Grad-CAM is computed.\n",
    "#         \"\"\"\n",
    "#         self.model.eval()\n",
    "\n",
    "#         # Forward pass\n",
    "#         feature_maps = None\n",
    "#         for name, module in self.model.named_modules():\n",
    "#             input_image = module(input_image)\n",
    "#             if name == self.target_layer:\n",
    "#                 feature_maps = input_image\n",
    "\n",
    "#         # Backward pass\n",
    "#         self.model.zero_grad()\n",
    "#         output = input_image[:, target_class]\n",
    "#         output.backward()\n",
    "\n",
    "#         # Generate heatmap\n",
    "#         gradients = self.gradients\n",
    "#         heatmap = self.generate_heatmap(feature_maps, gradients)\n",
    "#         return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df693b-4231-48d1-9a58-62d9b2c33984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.transforms.functional import to_pil_image\n",
    "# import cv2\n",
    "\n",
    "# def apply_gradcam(model, image_path, target_layer, label_map):\n",
    "#     \"\"\"\n",
    "#     Apply Grad-CAM to a single image.\n",
    "#     Args:\n",
    "#     - model: Trained PyTorch model.\n",
    "#     - image_path: Path to the input image.\n",
    "#     - target_layer: Target layer for Grad-CAM.\n",
    "#     - label_map: Dictionary mapping labels to class names.\n",
    "#     \"\"\"\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Resize((224, 224)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "\n",
    "#     # Load and preprocess image\n",
    "#     image = Image.open(image_path).convert(\"RGB\")\n",
    "#     input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "#     # Get prediction\n",
    "#     with torch.no_grad():\n",
    "#         output = model(input_tensor)\n",
    "#         pred_class = torch.sigmoid(output).item() > 0.5  # Binary prediction\n",
    "#         pred_label = label_map[int(pred_class)]\n",
    "\n",
    "#     # Apply Grad-CAM\n",
    "#     gradcam = GradCAM(model, target_layer)\n",
    "#     heatmap = gradcam(input_tensor, int(pred_class))\n",
    "\n",
    "#     # Visualize heatmap\n",
    "#     heatmap_resized = cv2.resize(heatmap, (224, 224))\n",
    "#     heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
    "#     overlay = cv2.addWeighted(np.array(image), 0.5, heatmap_colored, 0.5, 0)\n",
    "\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.imshow(image)\n",
    "#     plt.title(f\"Original Image ({pred_label})\")\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.imshow(overlay)\n",
    "#     plt.title(\"Grad-CAM Heatmap\")\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Example Usage\n",
    "# label_map = {0: \"Real\", 1: \"Fake\"}\n",
    "# image_path = \"path/to/test/image.jpg\"\n",
    "# apply_gradcam(model, image_path, \"layer4\", label_map)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
